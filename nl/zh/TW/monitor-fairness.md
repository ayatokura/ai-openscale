---

copyright:
  years: 2018, 2019
lastupdated: "2019-03-28"

keywords: fairness, fairness monitor

subcollection: ai-openscale

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}

# 公平性
{: #mf-monitor}

公平性會監視您部署的偏誤，以利確保不同族群之間公平的輸出結果。
{: shortdesc}

## 瞭解公平性
{: #mf-understand}

{{site.data.keyword.aios_short}} 會在執行時期檢查所部署模型的偏誤。如果要偵測所部署模型的偏誤，您必須定義公平性屬性（例如「年齡」或「性別」），如以下[配置「公平性」監視器](#mf-config)中所詳述。

請務必在 Watson {{site.data.keyword.pm_short}} 中，指定模型或函數的輸出綱目，才能在 {{site.data.keyword.aios_short}} 中啟用偏誤檢查。您可以在 `store_model` API 的 meta 資料部分中，使用 `client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA` 內容來指定輸出綱目。如需相關資訊，請參閱 [WML 用戶端說明文件![「外部鏈結」圖示](../../icons/launch-glyph.svg "「外部鏈結」圖示")](http://wml-api-pyclient-dev.mybluemix.net/#repository){: new_window}。

### 如何運作
{: #mf-works}

在您配置「公平性」監視器之前，有一些重要的概念務必要瞭解。

- *公平性屬性*：這些是模型有可能顯現偏誤的模型屬性。以公平性屬性 **`Gender`** 為例，模型可能對於特定的性別值（`Female`、`Transgender` 等）有偏誤。另以公平性屬性 **`Age`** 為例，模型可能對於某年齡群（例如 `18 to 25`）的人群顯現偏誤。

- *參照 / 受監視值*：公平性屬性的值分成兩個不同的種類：「參照」和「受監視」。「受監視」值是指要作為判別對象的那些值。對於 **`Gender`** 等之類的公平性屬性而言，「受監視」值可以是 `Female` 和 `Transgender`。對於 **`Age`** 等之類的數值型公平性屬性而言，「受監視」值可以是 `[18-25]`。給定公平性屬性的其他所有值則可視為參照值，例如 `Gender=Male` 或 `Age=[26,100]`。

- *有利 / 不利輸出結果*：模型的輸出會分類成「有利」或「不利」。舉例來說，如果模型預測某人是否應取得貸款，則「有利」輸出結果可以是 `Loan Granted` 或 `Loan Partially Granted`，而「不利」輸出結果可能是 `Loan Denied`。因此，「有利」輸出結果就是被視為正面輸出結果的那一個，而「不利」輸出結果則被視為負面。

{{site.data.keyword.aios_short}} 演算法會使用有效負載記載表格中所呈現的最近 `N` 筆記錄，每小時計算一次偏誤；`N` 值是在配置「公平性」時指定的。演算法會擾動這最近 `N` 筆記錄，以產生額外的資料。

擾動的作法是將公平性屬性的值從「參照」變更為「受監視」，反之亦然。之後會將擾動資料傳送給模型，以評估其行為。演算法會查看有效負載表格中的最近 `N` 筆記錄，以及查看模型在擾動資料上的行為，來決定模型是否以偏誤的方式執行。

在這個組合的資料集中，如果「受監視」類別的「有利」輸出結果百分比，小於「參照」類別的「有利」輸出結果百分比達到某個臨界值，就會將該模型視為有偏誤。此臨界值是在配置「公平性」時指定的。

公平性值可以超過 100%。這表示「受監視」群組所收到的有利輸出結果超過「參照」群組。此外，只要沒有傳送任何新的評分要求，「公平性」值會維持不變。
{: note}

### 範例
{: #mf-ex1}

假設有一個資料點，其中 `Gender=Male`（「參照」值），模型預測為「有利」輸出結果，但是當將 `Gender` 變更為 `Female`（「受監視」值），來擾動記錄時，儘管其他所有的特性值都維持相同，模型卻預測為「不利」輸出結果。如果資料點足夠（有效負載表格中的最近 `N` 筆記錄，外加擾動資料），但模型在這些資料點中卻以偏誤的方式執行，則該模型整體來說是顯現偏誤。

### 支援的模型
{: #mf-supmo}

 {{site.data.keyword.aios_short}} 只支援對那些模型以及預期其特性向量中存在某種結構化資料的 Python 函數，執行偏誤偵測。

## 配置「公平性」監視器
{: #mf-config}

1.  從*何謂公平性？*頁面中，按**下一步**，啟動配置處理程序。

    ![「何謂公平性？」頁面](images/fair-what-is.png)

1.  在*選取要監視的特性*頁面上，尋找並選取您要使用的公平性屬性，然後按**下一步**。

    只支援種類、數值（整數）、浮點或倍精準數公平性資料類型的特性。不支援其他資料類型的特性。
    {: note}

    在本例中，已選取 `Age`、`Gender` 和 `Ethnicity` 特性。

    ![具有一些選擇項的「選取要監視的特性」頁面](images/fair-select-feature.png)

    按**下一步**以繼續。

1.  每一項特性都有特定的需求要配置。在本例中，您將手動在「參照群組」和「受監視群組」中直接輸入值，以針對每一個群組定義 **`Age`** 範圍。

    在本例中，對於 **`Age`** 公平性屬性，如果您感覺您的模型有可能對於 18 歲到 25 歲人群有偏誤，則「受監視群組」值會是 `[18-25]`，而「參照群組」值會是 `[26-100]`。以 **`Gender`** 公平性屬性來說，「參照群組」值可能是 `Male`，而「受監視群組」值可能是 `Female` 和 `Transgender`。

    ![配置年齡設定](images/fair-config-age.png)

    按**下一步**以繼續。

1.  針對 **`Age`**，設定「公平性」的臨界值限制。

    「公平性」臨界值用來指定相較於「參照」群組的「有利」輸出結果百分比，對於「受監視」群組的「有利」輸出結果百分比，所能接受的差異。

    假設模型會預測何人應取得貸款 (`favorable outcome=loan granted`)，何人不應取得貸款 (`unfavorable outcome=loan denied`)。再者，年齡的「受監視」值是 `[18,25]`，「參照」值是 `[26,100]`。當執行偏誤偵測演算法時，如果發現在最近 `N` 筆記錄外加擾動資料中，年齡群 `[18,25]` 之人群的「有利」輸出結果百分比是 `50%`，而年齡群 `[26,100]` 之人群的「有利」輸出結果百分比是 `70%`，則所算出的「公平性」會是 50*100/70 = 71.42。

    如果「公平性」臨界值設為 80%，則演算法會將模型標示為有偏誤，這是因為所算出的「公平性」低於臨界值。不過，如果臨界值設為 70%，就不會將模型報告為有偏誤。

    ![配置年齡設定](images/fair-config-age-limit.png)

    選好「公平性」臨界值之後，請按**下一步**。

1.  以相同作法來配置 `Gender` 和 `Ethnicity` 特性：

     ![配置性別設定](images/fair-config-gender.png)

     ![配置種族設定](images/fair-config-ethnic.png)

     **附註**：您在這些畫面中輸入的值，應會成為要傳送給模型評分端點的值（因而會新增至有效負載表格中）。如果資料在傳送給評分端點之前會先進行操作，請輸入操作後的值。例如，如果原始資料的 *Gender* 值是 `Male` 和 `Female`，且經過操作，以致於傳送給評分端點的資料是 `M` 和 `F`，請在此畫面上輸入 `M` 和 `F`。

     當您完成每一項特性時，請按**下一步**。

1.  現在，請指定一些值來代表模型的有利輸出結果。如果模型輸出綱目含有對映直欄，這些值會衍生自訓練資料中的 `label` 直欄。在 WML 中，`prediction` 直欄一律具有倍精準數值。對映直欄用來指定這個 `prediction` 值指向類別標籤的對映。

    例如，如果 `prediction` 值是 `1.0`，對映直欄的值可能是 `Loan denied`；這意味著模型的預測是 `Loan denied`。因此，如果模型輸出綱目包含對映直欄，請使用對映直欄中的值來指定「有利」值和「不利」值。

    不過，如果模型輸出綱目中沒有對映直欄，則需要使用 `prediction` 直欄的值（`0.0`、`1.0` 等）來指定「有利」值和「不利」值。

     ![配置輸出結果](images/fair-config-outcome.png)

     按**下一步**。

1.  最後，設定樣本大小下限，以便在評估資料集中的可用記錄數目未達下限之前，阻止測量「公平性」。這是確保樣本大小不會太小而扭曲結果。每當執行偏誤檢查時，會使用樣本大小下限來決定將執行偏誤計算的記錄數目。

     ![配置樣本大小](images/fair-config-sample.png)

1.  按**下一步**按鈕。

    會呈現您的選擇摘要，供您檢閱。只要您想變更，請針對該區段按一下**編輯**鏈結。

    您也可以選取**新增另一特性**鏈結，回到特性選取畫面，並新增其他特性至「公平性」監視器，例如：`City`、`Zip Code` 或 `Account Balance`。

1.  按一下**儲存**，以完成配置。

### 瞭解除去偏誤如何運作
{: #mf-debias}

之後會呈現一個畫面，其中提供一個已除去偏誤的評分端點。

  ![除去偏誤 API](images/fair-debias-api.png)

已除去偏誤的評分端點可完全當成所部署模型正常的評分端點使用。除了傳回所部署模型的回應之外，還會額外傳回兩個直欄，稱為 `debiased_prediction` 和 `debiased_probability`。

- `debiased_prediction` 直欄含有已除去偏誤的預測值。對 Watson Machine Learning (WML) 而言，這是以編碼方式來表示預測。例如，如果模型預測是 "Loan Granted" 或 "Loan Denied"，WML 可將這兩個值分別編碼成 "0.0" 和 "1.0"。 `debiased_prediction` 直欄含有這類以編碼方式來表示已除去偏誤的預測。

- 在另一方面，`debiased_probability` 直欄代表已除去偏誤之預測的機率。這是一個倍精準數值陣列，其中，每一個值各代表已除去偏誤之預測（屬於其中一個預測類別）的機率。

假設您的輸出綱目中有一個直欄，且該直欄含有一個 `modeling-role` 設為 `decoded-target` 的直欄，也會傳回另一個直欄 `debiased_decoded_target`。

- `debiased_decoded_target` 直欄會以字串來表示已除去偏誤的預測。在上例中，預測值是 "0.0" 或 "1.0"，`debiased_decoded_target` 將包含 "Loan Granted" 或 "Loan Denied"。

理論上，您會從正式作業應用程式直接呼叫此端點，而不是直接呼叫部署在模型處理引擎（Watson Machine Learning、Amazon Sagemaker、Microsoft Azure ML Studio 等）中之模型的評分端點。這樣一來，{{site.data.keyword.aios_short}} 也會將 `debiased` 值儲存在您模型部署的有效負載記載表格中。之後，凡是透過此端點來完成的評分都會自動除去偏誤。

由於此端點會處理執行時期偏誤，它會繼續對有效負載記載表格中的最新評分資料執行背景檢查，並持續更新偏誤減輕模型（此模型用來去除所傳送之評分要求的偏誤）。在此情況下，{{site.data.keyword.aios_short}} 一律保有最新的送入資料，且其在偵測及減輕偏誤的行為上也會保持最新。

最後，{{site.data.keyword.aios_short}} 使用臨界值決定該資料現在是可接受的，且可視為無偏誤。對於在「公平性」監視器中設定給所配置之所有公平性屬性的臨界值中，會以該臨界值作為最小值。

### 後續步驟
{: #mf-next}

從*配置監視器*頁面，您可以選取另一個監視種類。
