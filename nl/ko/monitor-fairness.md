---

copyright:
  years: 2018, 2019
lastupdated: "2019-06-24"

keywords: fairness, fairness monitor

subcollection: ai-openscale

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}

# 공정성
{: #mf-monitor}

공정성은 서로 다른 인구 전체에 걸쳐 공정한 결과가 보장되도록 돕기 위해 배치의 편향성을 모니터합니다.
{: shortdesc}

## 공정성 이해
{: #mf-understand}

{{site.data.keyword.aios_short}}은 런타임 시에 배치 모델의 편향성을 검사합니다. 배치된 모델에 대한 편향성을 발견하려면 아래의 [공정성 모니터 구성](#mf-config)에서 자세히 설명하는 것과 같이 연령 또는 성별 등의 공정성 속성을 정의해야 합니다.

{{site.data.keyword.aios_short}}에서 편향성 검사를 사용할 수 있도록 Watson {{site.data.keyword.pm_short}}에서 모델 또는 함수에 대한 출력 스키마를 지정하는 것은 필수입니다. 출력 스키마는 `store_model` API의 메타데이터 파트에서 `client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA` 특성을 사용하여 지정할 수 있습니다. 자세한 정보는 [WML 클라이언트 문서 ![외부 링크 아이콘](../../icons/launch-glyph.svg "외부 링크 아이콘")](http://wml-api-pyclient-dev.mybluemix.net/#repository){: new_window}를 참조하십시오.

### 작동 방식
{: #mf-works}

공정성 모니터를 구성하기 전에 이해해야 하는 몇 가지 중요한 개념이 있습니다.

- *공정성 속성*: 모델이 편향성을 나타내기 쉬운 모델 속성입니다. 예를 들어, 공정성 속성 **`Gender`**의 경우, 모델이 특정 성별 값(`Female`, `Transgender` 등)에 대해 편향될 수 있습니다. 공정성 속성의 또 다른 예로는 **`Age`**가 있으며 모델이 `18 - 25` 등의 연령 그룹에서 편향성을 나타낼 수 있습니다.

- *참조/모니터되는 값*: 공정성 속성의 값은 참조 및 모니터라는 두 개의 구별되는 카테고리로 나뉩니다. 모니터되는 값은 구별할 수 있는 가능성이 높은 값입니다. **`Gender`**와 같은 공정성 속성의 경우, 모니터되는 값이 `Female` 및 `Transgender`일 수 있습니다. **`Age`**와 같은 숫자 공정성 속성의 경우, 모니터되는 값이 `[18-25]`일 수 있습니다. 지정된 공정성 속성에 대한 모든 기타 값은 참조 값으로 간주됩니다. 예를 들어, `Gender=Male` 또는 `Age=[26,100]`입니다.

- *선호/비선호 결과*: 모델의 결과가 선호 또는 비선호로 분류됩니다. 예를 들어, 모델이 한 개인이 대출을 받을 수 있는지 여부를 예측하는 경우, 선호 결과는 `Loan Granted` 또는 `Loan Partially Granted`인 반면 비선호 결과는 `Loan Denied`일 수 있습니다. 따라서 선호 결과가 긍정적인 결과로 간주되는 반면 비선호 결과는 부정적인 것으로 간주됩니다.

{{site.data.keyword.aios_short}} 알고리즘은 페이로드 로깅 테이블에 있는 최근 `N`개의 레코드를 사용하여 매시간 기준으로 편향성을 계산합니다. `N`의 값은 공정성을 구성할 때 지정됩니다. 알고리즘은 최근 `N`개의 레코드를 섭동하여 추가 데이터를 생성합니다.

섭동은 공정성 속성의 값을 참조에서 모니터로 또는 반대로 변경하여 수행됩니다. 섭동된 데이터는 작동을 평가하기 위해 모니터로 전송됩니다. 알고리즘은 페이로드 테이블 내의 최근 `N`개의 레코드와 섭동된 데이터에 대한 모델의 동작을 관찰하여 모델이 편향된 방식으로 작동하는지 여부를 결정합니다.

결합된 이 데이터 세트 전체에 걸쳐 모니터되는 클래스의 선호 결과의 백분율이 지정된 임계값 차이 이상으로 참조 클래스에 대한 선호 결과의 백분율 미만이면 모델이 편향된 것으로 간주됩니다. 이 임계값은 공정성을 구성할 때 지정됩니다.

공정성 값은 100% 보다 클 수 있습니다. 이는 모니터 대상 그룹이 참조 그룹보다 많은 선호 결과를 수신했음을 의미합니다. 또한, 새 스코어링 요청이 전송되지 않는 경우에는 공정성 값이 변경되지 않습니다.
{: note}

### 편향성 시각화 ![베타 태그](images/beta.png)
{: #mf-monitor-bias-viz}

잠재적 편향성이 발견된 경우 {{site.data.keyword.aios_short}}은 여러 기능을 수행하여 편향성이 실제인지 여부를 확인합니다. {{site.data.keyword.aios_short}}은 모니터된 값을 참조 값으로 플립한 후 모델을 통해 이 새 레코드를 실행하여 모니터를 섭동합니다. 그리고 이는 결과 출력을 편향성 제거된 출력으로 표면화합니다. 또한 {{site.data.keyword.aios_short}}은 새도우 편향성 제거된 모델을 훈련시키며, 이는 다시 모델이 편향된 예측을 작성할 때 발견에 사용됩니다. 이러한 결정의 결과는 다음 보기가 포함된 편향성 시각화에서 사용 가능합니다.  

- **페이로드 + 섭동됨**: 선택한 시간 동안 수신된 스코어링 요청 및 평가에 필요한 최소 레코드 수가 충족되지 않은 경우 이전 시간의 추가 레코드를 포함합니다. 모니터 대상 기능의 값이 변경되는 경우 모델의 응답을 테스트하는 데 사용되는 추가적인 섭동된/합성된 레코드가 포함됩니다.

   다음 페이로드 및 섭동된 세부사항을 기록해 두십시오.

   - 페이로드 테이블에서 이 시간에 읽힌 레코드의 수
   - 이전 시간에서 읽는 추가 레코드(예를 들어, 공정성 구성의 `min_records` 값이 1000으로 설정되어 있고 최소 요구사항을 충족시키기 위해 오후 2시에서 3시 사이에 10개 레코드만 추가되는 경우, 시스템은 추가로 이전 시간의 990개 레코드를 읽습니다.)
   - 공정성 속성별 섭동된 레코드 수
   - 편향성을 계산해야 하는 데이터 프레임의 가장 오래된 레코드 시간소인
   - 편향성을 계산해야 하는 데이터 프레임의 가장 최신 레코드 시간소인

  ![페이로드 및 섭동됨 예](images/payload&perturbed.png)



- **페이로드**: 선택한 시간 동안 모델에서 수신한 실제 스코어링 요청입니다.

   다음 페이로드 세부사항을 기록해 두십시오.
   
   - 페이로드 테이블에서 편향성 제거된 오퍼레이션이 수행되는/읽는 레코드의 수
   - 편향성을 계산해야 하는 데이터 프레임의 가장 오래된 레코드 시간소인
   - 편향성을 계산해야 하는 데이터 프레임의 가장 최신 레코드 시간소인


  ![페이로드 데이터의 예](images/payload.png)

- **훈련**: 모델을 훈련시키는 데 사용되는 훈련 데이터 레코드입니다.

   다음 훈련 세부사항을 기록해 두십시오.
   
   - 훈련 데이터 레코드의 수. 훈련 데이터는 한번 읽혀지며 분포는 `subscription/fairness_configuration` 변수에 저장됩니다. 분포를 계산하는 동안 훈련 데이터 레코드의 수를 찾아서 동일한 분포에 저장해야 합니다. 또한 훈련 데이터가 변경되는 경우(`POST /data_distribution` 명령이 다시 실행되는 경우를 의미함) 이 값은 `fairness_configuration/training_data_distribution` 변수에서 업데이트됩니다. 메트릭을 전송하는 동안 이 값도 전송해야 합니다.
   - 훈련 데이터가 마지막으로 처리되는 시간(첫 번째 및 후속 업데이트)

  ![훈련 데이터의 예](images/training.png)
   

   
- **편향성 제거됨**: 런타임 및 섭동된 데이터를 처리한 후 편향성 제거 알고리즘의 결과입니다.

   다음 편향성 제거됨의 세부사항을 기록해 두십시오.
   
   - 페이로드 테이블에서 편향성 제거된 오퍼레이션이 수행되는/읽는 레코드의 수
   - 편향을 수행하기 위해 읽혀지는 추가 레코드 및 그로 인해 편향성 제거된 레코드 수. `Payload + Perturbed` 선택의 수와 동일한 수입니다.
   - 공정성 속성별 섭동된 레코드 수
   - 편향성을 계산해야 하는 데이터 프레임의 가장 오래된 레코드 시간소인
   - 편향성을 계산해야 하는 데이터 프레임의 가장 최신 레코드 시간소인

  ![편향성 제거된 데이터의 예](images/debiased.png)
  
### 예
{: #mf-ex1}

`Gender=Male`(참조 값)인 데이터 점을 고려하면 모델이 선호 결과를 예측하나 `Gender`를 `Female`(모니터되는 값)로 변경하여 섭동된 레코드인 경우, 모든 기타 특성은 동일하게 유지되나 모델이 비선호 결과를 예측합니다. (페이로드 테이블 내의 최근 `N`개의 레코드 더하기 섭동된 데이터에 걸쳐) 모델에 편향된 방식으로 작동하는 데이터 점이 충분한 경우, 모델이 전체적으로 편향성을 보인다고 합니다.

### 지원되는 모델
{: #mf-supmo}

 {{site.data.keyword.aios_short}}은 특성 벡터 내에 일부 종류의 정형 데이터를 예상하는 모델 및 Python 함수에 대해서만 편향성 발견을 지원합니다.

## 공정성 모니터 구성
{: #mf-config}

1.  *공정성의 개념* 페이지에서 **다음**을 클릭하여 구성 프로세스를 시작하십시오.

    ![공정성의 개념 페이지](images/fair-what-is.png)

1.  *모니터할 특성 선택* 페이지에서 사용할 공정성 속성을 찾아서 선택하고 **다음**을 클릭하십시오.

    카테고리, 숫자(정수), 부동 또는 이중 공정성 데이터 유형의 특성만 지원됩니다. 기타 데이터 유형의 특성은 지원되지 않습니다.
    {: note}

    이 예에서는 `Age`, `Gender` 및 `Ethnicity` 특성이 선택되었습니다.

    ![선택사항이 있는 모니터할 특성 선택 페이지](images/fair-select-feature.png)

    **다음**을 클릭하여 계속하십시오.

1.  각 특성을 구성하기 위한 특정 요구사항이 있습니다. 이 예에서는 각 그룹에 값을 수동으로 직접 입력하여 참조 그룹 및 모니터되는 그룹으로 **`Age`** 범위를 정의합니다.

    이 예에서, **`Age`** 공정성 속성의 경우, 나이가 18세에서 25세 사이인 사람에 대해 모델이 편향될 확률이 높은 것으로 판단되면 모니터되는 그룹 값이 `[18-25]`가 되고 참조 그룹 값이 `[26-100]`이 됩니다. **`Gender`** 공정성 속성의 경우, 참조 그룹 값이 `Male`일 수 있는 반면 모니터되는 그룹 값은 `Female` 및 `Transgender`일 수 있습니다.

    ![연령 설정 구성](images/fair-config-age.png)

    **다음**을 클릭하여 계속하십시오.

1.  **`Age`**에 대해 공정성 임계값 한계를 설정하십시오.

    공정성 임계값은 참조 그룹에 대한 선호 결과의 백분율과 비교하여 모니터되는 그룹에 대한 선호 결과의 백분율의 허용 가능한 차이를 지정하는 데 사용됩니다.

    대출을 받을 수 있는 사람(`favorable outcome=loan granted`) 및 받을 수 없는 사람(`unfavorable outcome=loan denied`)을 예측하는 모델을 고려해 보십시오. 또한 연령에 대해 모니터되는 값은 `[18,25]`이며 참조 값은 `[26,100]`입니다. 편향성 발견 알고리즘이 실행될 때, 최근 `N`개의 레코드 더하기 섭동된 데이터에서 연령 그룹 `[18,25]` 내의 사람에 대한 선호 결과의 백분율이 `50%` 인 반면, 연령 그룹 `[26,100]` 내의 사람에 대한 선호 결과의 백분율이 `70%`이면 공정성이 50*100/70 = 71.42인 것으로 계산됩니다.

    공정성 임계값이 80%로 설정된 경우, 계산된 공정성이 임계값보다 낮으므로 알고리즘이 모델을 편향된 것으로 플래그 지정합니다. 단, 임계값이 70%로 설정되면 모델을 편향된 것으로 보고하지 않습니다.

    ![연령 설정 구성](images/fair-config-age-limit.png)

    공정성 임계값을 선택했으면 **다음**을 클릭하십시오.

1.  동일한 방법으로 `Gender` 및 `Ethnicity` 특성을 구성하십시오.

     ![성별 설정 구성](images/fair-config-gender.png)

     ![인종 설정 구성](images/fair-config-ethnic.png)

     **참고**: 해당 화면에 입력하는 값이 모델 스코어링 엔드포인트에 전송한 값이어야 합니다. 결과적으로 페이로드 테이블에 추가됩니다. 데이터를 스코어링 엔드포인트로 전송하기 전에 조작한 경우, 조작된 값을 입력하십시오. 예를 들어, 원래 데이터의 값이 *Gender*에 대해서는 `Male` 및 `Female`이며 스코어링 엔드포인트로 전송된 데이터가 `M` 및 `F`로 조작된 경우, 이 화면에서는 `M` 및 `F`입니다.

     각 특성에 대해 수행을 완료하였으면 **다음**을 클릭하십시오.

1.  이제 모델에 대한 선호 결과를 표시하는 값을 지정하십시오. 모델 출력 스키마에 맵핑 열이 있는 경우 [훈련 데이터](/docs/services/ai-openscale?topic=ai-openscale-trainingdata#trainingdata)의 `label` 열에서 값이 파생됩니다. WML에서는 `prediction` 열에 항상 이중 값이 있습니다. 맵핑 열은 이 `prediction` 값을 클래스 레이블에 맵핑하는 데 사용됩니다.

    예를 들어, `prediction` 값이 `1.0`이면 맵핑 열이 `Loan denied` 값을 가질 수 있습니다. 이는 모델의 예측이 `Loan denied`임을 의미합니다. 따라서 모델 출력 스키마가 맵핑 열을 포함하면 맵핑 열에 있는 해당 사항을 사용하여 선호 및 비선호 값을 지정합니다.

    단, 모델 출력 스키마에 맵핑 열이 없으면 선호 및 비선호 값이 `prediction` 열의 값(`0.0`, `1.0` 등)을 사용하여 지정되어야 합니다.

     ![결과 구성](images/fair-config-outcome.png)

     **다음**을 클릭하십시오.

1.  마지막으로 평가 데이터 세트에서 최소 수의 레코드가 사용 가능할 때까지 공정성 측정을 금지하도록 최소 샘플 크기를 설정하십시오. 이로 인해 샘플 크기가 너무 작아서 결과를 왜곡시키는 것을 방지할 수 있습니다. 편향성 검사가 실행될 때마다 최소 샘플 크기를 사용하여 편향성 계산을 수행할 레코드 수를 결정합니다.

     ![샘플 크기 구성](images/fair-config-sample.png)

1.  **다음** 단추를 클릭하십시오.

    검토를 위해 선택사항 요약이 표시됩니다. 변경해야 할 사항이 있으면 해당 섹션의 **편집** 링크를 클릭하십시오.

    또한 **다른 특성 추가** 링크를 선택하여 특성 선택 화면으로 돌아가서 공정성 모니터에 특성을 계속 추가할 수 있습니다. 예를 들어, `City`, `Zip Code` 또는 `Account Balance`가 있습니다.

1.  **저장**을 클릭하여 구성을 완료하십시오.

### 편향성 제거 작업 이해
{: #mf-debias}

편향성이 제거된 스코어링 엔드포인트를 제공하는 화면이 표시됩니다.

  ![편향성 제거 API](images/fair-debias-api.png)

편향성이 제거된 스코어링 엔드포인트는 배치된 모델의 일반 스코어링 엔드포인트와 완전히 동일하게 사용될 수 있습니다. 배치된 모델의 응답을 리턴하는 것 외에 `debiased_prediction` 및 `debiased_probability`라는 두 개의 추가 열을 리턴합니다.

- `debiased_prediction` 열은 편향성 제거된 예측 값을 포함합니다. Watson Machine Learning(WML)의 경우, 예측의 인코딩된 표현입니다. 예를 들어, 모델 예측이 "Loan Granted" 또는 "Loan Denied"인 경우, WML이 이러한 두 값을 각각 "0.0" 및 "1.0"으로 인코딩할 수 있습니다. `debiased_prediction` 열은 편향성 제거된 예측의 인코딩된 표현 등을 포함합니다.

- 반면에 `debiased_probability` 열은 편향성 제거된 예측의 확률을 표시합니다. 각 값이 예측 클래스 중 하나에 속하는 편향성 제거된 예측의 확률을 나타내는 이중 값의 배열입니다.

`decoded-target`으로 `modeling-role`이 있는 열을 포함하는 출력 스키마 내에 열이 있는 경우, 다른 열인 `debiased_decoded_target`도 리턴됩니다.

- `debiased_decoded_target` 열은 편향성 제거된 예측의 문자열 표현을 포함합니다. 예측 값이 "0.0" 또는 "1.0"인 위 예에서는 `debiased_decoded_target`이 "Loan Granted" 또는 "Loan Denied"를 포함할 것입니다.

모델 수행 엔진(Watson Machine Learning, Amazon Sagemaker, Microsoft Azure ML Studio 등)에 배치된 스코어링 엔드포인트를 직접 호출하는 대신 프로덕션 애플리케이션에서 이 엔드포인트를 호출하는 것이 이상적입니다. 이 방법을 사용하면 {{site.data.keyword.aios_short}}이 `debiased` 값도 모델 배치의 페이로드 로깅 테이블에 저장합니다. 그런 다음 이 엔드포인트를 통해 수행된 모든 스코어링이 자동으로 편향성 제거됩니다.

이 엔드포인트가 런타임 편향성을 처리하므로 페이로드 로깅 테이블에서 최신 스코어링 데이터에 대해 계속 백그라운드 검사를 실행하며 전송된 스코어링 요청을 편향성 제거하는 데 사용되는 편향성 완화 모델을 계속 업데이트합니다. 이런 방법으로 {{site.data.keyword.aios_short}}이 항상 최신 수신 데이터 및 편향성을 감지하고 완화하기 위한 동작을 사용하여 최신 상태로 유지됩니다.

최종적으로 {{site.data.keyword.aios_short}}이 임계값을 사용하여 데이터가 허용 가능하며 편향되지 않았다고 간주되는지 결정합니다. 임계값은 구성된 모든 공정성 속성에 대해 공정성 모니터에서 설정된 임계값의 최신 값으로 사용됩니다.

### 다음 단계
{: #mf-next}

*모니터 구성* 페이지에서 다른 모니터링 카테고리를 선택할 수 있습니다.
