---

copyright:
  years: 2018, 2019
lastupdated: "2019-06-28"

keywords: fairness, fairness monitor, payload, perturbation, training data, debiased

subcollection: ai-openscale

---

{:shortdesc: .shortdesc}
{:external: target="_blank" .external}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:pre: .pre}
{:codeblock: .codeblock}
{:download: .download}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}
{:faq: data-hd-content-type='faq'}

# 公平性モニターの構成
{: #mf-monitor}

{{site.data.keyword.aios_full}} では、公平性モニターを使用してデプロイメントにバイアスがないかスキャンし、集団によらず公平な結果が得られるようにすることができます。
{: shortdesc}

## 手順
{: #mf-config}

**「公平性」**タブの**「公平性モニターとは (What is Fairness?)」**ページで、**「開始」**をクリックして、構成プロセスを開始します。

![「公平性モニターとは (What is Fairness?)」ページ](images/fair-what-is.png)

このプロセスを通して、{{site.data.keyword.aios_full}} はモデルを分析し、最も論理的な結果に基づいて推奨を行います。 **「公平性」**タブの一連のページで、以下のタスクを実行する必要があります。

1. モニターする特徴量を選択します。 公平性のデータ・タイプが、カテゴリカル、数値 (整数)、浮動小数点、または倍精度の特徴量だけがサポートされます。 他のデータ・タイプの特徴量はサポートされません。

1. 参照グループとモニター対象グループを指定します。

   各特徴量には構成に関する特定の要件があります。 例えば、モニタリング対象の特徴量の 1 つとして `age` を選択した場合、**「参照グループ」**と**「モニター対象グループ」**に値を直接入力して、それらのグループの年齢範囲を定義する必要があります。

1.  特徴量の公平性アラートしきい値を設定します。

    公平性しきい値は、モニター対象グループの好ましい結果の割合を参照グループの好ましい結果の割合と比較したときの受け入れ可能な差異を指定するときに使用します。

    融資が許可される申請者 (`favorable outcome=loan granted`) と融資が許可されない申請者 (`unfavorable outcome=loan denied`) を予測するモデルがあるとします。 また、年齢のモニター対象値は `[18,25]`、参照値は `[26,100]` です。 バイアス検出アルゴリズムの実行時に、最新 `N` 件のレコードと摂動されたデータで年齢グループ `[18,25]` の申請者の好ましい結果の割合が `50%` であり、年齢グループ `[26,100]` の申請者の好ましい結果の割合が `70%` である場合、公平性は 50*100/70 = 71.42 と計算されます。

    公平性しきい値が 80% に設定されている場合は、計算された公平性がこのしきい値を超えるため、アルゴリズムによりこのモデルにバイアスがあることを示すフラグが立てられます。 ただし、しきい値が 70% に設定されている場合、このモデルはバイアスがあるものとして報告されません。

     これらの画面で入力する値は、モデル評価エンドポイントに送信される値である必要があります (結果的には、ペイロード・テーブルに追加されます) 。 データが予測エンドポイントへの送信前に操作された場合は、操作後の値を入力してください。 例えば、元のデータの *Gender* の値 `Male` と `Female` が操作され、予測エンドポイントに送信されるデータが `M` と `F` になった場合、この画面では `M` と `F` を入力してください。

1.  モデルで好ましい結果を表す値を指定します。 モデル出力スキーマにマッピング列が含まれている場合、値は[訓練データ](/docs/services/ai-openscale?topic=ai-openscale-trainingdata#trainingdata)の `label` 列から得られます。 {{site.data.keyword.pm_full}} では、`prediction` 列の値は常に倍精度になります。 マッピング列は、この `prediction` 値からクラス・ラベルへのマッピングを指定するために使用されます。

    例えば、`prediction` 値が `1.0` の場合、マッピング列の値に `Loan denied` を設定することができます。これは、モデルの予測が `Loan denied` であることを示します。 それで、モデル出力スキーマにマッピング列が含まれている場合、マッピング列に存在する値を使用して好ましい値と好ましくない値を指定します。

    ただし、モデル出力スキーマにマッピング列がない場合、`prediction` 列の値を使用して、好ましい値と好ましくない値を指定する必要があります (`0.0`、`1.0` など)

1.  最後に、評価データ・セットで最小限の数のレコードを得られるまで公平性の測定を行わないようにするため、最小サンプル・サイズを設定します。 これにより、サンプル・サイズが小さすぎて結果にゆがみが生じることがなくなります。 バイアス検査が実行されるたびに、最小サンプル・サイズを使用してバイアス計算対象のレコードの数が決定されます。

    選択内容の要約が確認のために表示されます。 変更が必要な場合は、該当するセクションの**「編集」**リンクをクリックします。そうでない場合は、**「保存」**をクリックします。

    **「別の特徴量の追加」**をクリックして特徴量選択画面に戻り、公平性モニターに特徴量 (`City`、`Zip Code`、`Account Balance` など) を追加することもできます。

### バイアス緩和の処理の流れについて
{: #mf-debias}

バイアス緩和エンドポイントを確認するには、**「バイアス緩和エンドポイント (Debias Endpoint)」**ボタンをクリックします。 そして、そのエンドポイントをさまざまなフォーマット (cURL、Java、Python など) で表示およびコピーできます。 

バイアス緩和後の予測エンドポイントは、デプロイ済みモデルの通常のスコアリング・エンドポイントと完全に同じように使用できます。 このエンドポイントは、デプロイ済みモデルの応答を返すだけでなく、`debiased_prediction` 列と `debiased_probability` 列も返します。

- `debiased_prediction` 列にはバイアス緩和後の予測値が入ります。 {{site.data.keyword.pm_full}} の場合、これは予測のエンコード表現です。 例えば、モデルの予測が「Loan Granted」または「Loan Denied」の場合、{{site.data.keyword.pm_full}} ではこれらの 2 つの値をそれぞれ「0.0」と「1.0」にエンコードできます。 `debiased_prediction` 列には、このようなバイアス緩和後の予測のエンコード表現が入ります。

- 一方、`debiased_probability` 列は、バイアス緩和後の予測の確率を表します。 これは倍精度値の配列であり、各値はいずれかの予測クラスに属するバイアス緩和後の予測の確率を表します。

`decoded-target` として `modeling-role` が設定されている列を含んだ出力スキーマに列がある場合、`debiased_decoded_target` という別の列も返されます。

- `debiased_decoded_target` 列には、バイアス緩和後の予測のストリング表現が入ります。 前述の例では、予測値が「0.0」または「1.0」のいずれかである場合、`debiased_decoded_target` には「Loan Granted」または「Loan Denied」のいずれかが入ります。

このエンドポイントを実動アプリケーションから直接呼び出すほうが、モデル処理エンジン ({{site.data.keyword.pm_full}}、Amazon Sagemaker、Microsoft Azure ML Studio など) にデプロイされたモデルの予測エンドポイントを直接呼び出すよりも、理想的です。 このようにすると、{{site.data.keyword.aios_short}} は、モデル・デプロイメントのペイロード・ロギング・テーブルに `debiased` の値も格納します。 その後、このエンドポイントで行われたすべての予測は自動的にバイアス緩和されます。

このエンドポイントは実行時のバイアスに対処するので、ペイロード・ロギング・テーブルからの最新の予測データに対しバックグラウンド検査を引き続き実行し、送信された評価要求のバイアスを排除するために使用されるバイアス緩和モデルを更新し続けます。 このように、{{site.data.keyword.aios_short}} には、最新の着信データを取り込む機能と、バイアスを検出して緩和する機能があるので、常に最新状態に維持されます。

最後に {{site.data.keyword.aios_short}} は、データが現時点で受け入れ可能でバイアスがないものと判定するために、しきい値を使用します。 そのしきい値として取られる値は、公平性モニターで構成済みのすべての公平性属性に対して設定されたしきい値の中の最小値です。

## 次のステップ
{: #mf-next}

**「モニターの構成」**ページで、別のモニタリング・カテゴリーを選択できます。
