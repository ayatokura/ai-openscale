---

copyright:
  years: 2018, 2019
lastupdated: "2019-06-28"

keywords: metrics, monitoring, custom metrics, thresholds

subcollection: ai-openscale

---

{:shortdesc: .shortdesc}
{:external: target="_blank" .external}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:pre: .pre}
{:codeblock: .codeblock}
{:download: .download}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}
{:faq: data-hd-content-type='faq'}

# 公平性指標の概要
{: #anlz_metrics_fairness}

{{site.data.keyword.aios_full}} の公平性モニタリングを使用して、モデルによって生成された結果が、モニター対象グループにとって公平な結果かどうかを判別できます。 公平性モニタリングを有効にすると、デフォルトでは 1 時間ごとに指標のセットが生成されます。 これらの指標は、**「今すぐ品質を評価」**ボタンをクリックするか、Python クライアントを使用して、オンデマンドで生成できます。
{: shortdesc}

{{site.data.keyword.aios_short}} は、モデル内に既知の保護属性が存在するかどうかを自動的に検知します。 保護属性を検知すると、{{site.data.keyword.aios_short}} は、潜在的にセンシティブな属性についてのバイアスを稼働環境で確実に追跡するために、存在している各属性についてバイアス・モニターを構成するように自動的に推奨します。 

現在、{{site.data.keyword.aios_short}} が検出してモニターを推奨するのは、以下の保護属性です。 

- 性別
- 人種
- 婚姻状態
- 年齢
- 郵便番号

{{site.data.keyword.aios_short}} は、保護属性を検出するだけでなく、各属性のどの値をモニター対象値および参照値に設定すべきかについての推奨情報を生成します。 例えば、{{site.data.keyword.aios_short}} は、「性別」属性の「女性」と「ノンバイナリー」をモニター対象値に、「男性」を参照値にしてバイアス・モニターを構成することを推奨します。 推奨された項目を変更したい場合は、バイアス構成パネルで編集できます。 

推奨されたバイアス・モニターを利用すれば、構成を素早く完了して、センシティブな属性に対する AI モデルの公平性を確実に検査することができます。 規制当局がアルゴリズムのバイアスに目を光らせるようになった今、組織のモデルがどのように機能しているのか、また、特定のグループにとって不公平な結果を生成していないかについて、組織が明確に把握することがますます重要になっています。 

## 公平性について
{: #mf-understand}

{{site.data.keyword.aios_short}} は、デプロイ済みモデルを実行時に調べ、バイアスがあるかどうかを確認します。 デプロイ済みモデルのバイアスを検出するには、公平性属性 (Age、Gender など) を定義する必要があります。詳しくは、以下の[公平性モニターの構成](#mf-config)のセクションを参照してください。

{{site.data.keyword.aios_short}} でのバイアス検査を有効にするため、Watson {{site.data.keyword.pm_short}}でモデルまたは関数の出力スキーマを指定する必要があります。 出力スキーマは、`store_model` API のメタデータ部分で `client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA` プロパティーを使用して指定できます。 詳しくは、[{{site.data.keyword.pm_full}} クライアント資料](http://wml-api-pyclient-dev.mybluemix.net/#repository){: external}を参照してください。

### 処理の流れ
{: #mf-works}

公平性モニターを構成する前に、理解しておくべき重要な概念がいくつかあります。

- 公平性属性とは、バイアスが現れる可能性のあるモデルの属性のことです。 例えば、公平性属性 **`Gender`** の場合、モデルでは特定の性別値 (`Female`、`Transgender` など) にに対してバイアスが現れる可能性があります。 公平性属性のもう 1 つの例が **`Age`** です。モデルで特定の年齢グループ (`18 to 25` など) に属する人々に対してバイアスが現れる可能性があります。

- 参照値/モニター対象値: 公平性属性の値は、「参照値」と「モニター対象値」という 2 つの別個のカテゴリーに分けられます。 モニター対象値とは、不公平な判断をされる可能性がある値です。 **`Gender`** のような公平性属性の場合、モニター対象値は `Female` と `Transgender` などになります。 **`Age`** のような数値の公平性属性の場合、モニター対象値は `[18-25]` などになります。 特定の公平性属性のモニター対象値以外のすべての値は、参照値として扱われます (例: `Gender=Male`、`Age=[26,100]` など)。

- 好ましい結果/好ましくない結果: モデルの出力は、「好ましい」または「好ましくない」のいずれかに分類されます。 例えば、モデルで融資の申請が受理されるかどうかを予測する場合には、好ましい結果は `Loan Granted` や `Loan Partially Granted` などで、好ましくない結果は `Loan Denied` などになります。 したがって、好ましい結果とは肯定的と見なされる結果で、好ましくない結果とは否定的と見なされる結果です。

{{site.data.keyword.aios_short}} アルゴリズムは、ペイロード・ロギング・テーブルの最新 `N` 件のレコードを使用して、1 時間ごとにバイアスを計算します (`N` の値は、公平性の構成時に指定します)。 このアルゴリズムはこれら最新の `N` 件のレコードを摂動して追加データを生成します。

この摂動は、公平性属性の値を参照値からモニター対象値 (またはこの逆方向) に変更することで行われます。 摂動されたデータはモデルに送られ、その動作が評価されます。 このアルゴリズムはペイロード・テーブルの最新 `N` 件のレコードと、摂動されたデータに対するモデルの動作を調べ、モデルがバイアス挙動を示しているかどうかを判定します。

結合されたこのデータ・セットでモニター対象クラスの好ましい結果の割合が、参照クラスの好ましい結果の割合よりも低く、その差がしきい値を超えた場合は、モデルにバイアスがあると見なされます。 このしきい値は、公平性の構成時に指定します。

公平性値は 100% を超えることがあります。これは、モニター対象グループが得る好ましい結果が参照グループより多いことを意味します。 また、新しい評価要求が送信されない場合は、公平性値は一定のままになります。
{: note}

### 計算
{: #mf-bias-math}

{{site.data.keyword.aios_short}} で使用される公平性メトリックは、差別的効果 (disparate impact) です。これは、優遇されるグループが特定の成果または結果を受け取る割合と、優遇されないグループがその同じ結果を受け取る割合を比較する指標です。

差別的効果の計算には次の数式が使用されます。

```
                     (num_positives(privileged=False) / num_instances(privileged=False))
差別的効果 =   ______________________________________________________________________

                     (num_positives(privileged=True) / num_instances(privileged=True))
```

この場合、`num_positives` は、グループ (privileged=False (優遇されないグループ) または privileged=True (優遇されるグループ) のいずれか) の中で肯定的な結果を受け取った人数で、num_instances はグループの合計人数です。

結果の数値はパーセンテージで表されます。つまり、優遇されるグループが肯定的な結果を受け取る割合に対する、優遇されないグループが肯定的な結果を受け取る割合の比率を表すパーセンテージです。 例えば、信用リスク・モデルで、優遇されない申請者については 80% が「リスクなし」と予測され、優遇される申請者については 100% が「リスクなし」と予測された場合、このモデルの差別的効果は 80% になります ({{site.data.keyword.aios_short}} で公平性スコアとして表示されます)。

{{site.data.keyword.aios_short}} では、肯定的な結果を好ましい結果として表し、否定的な結果を好ましくない結果として表します。 優遇されるグループを参照グループとして表し、優遇されないグループをモニター対象グループとして表します。


### バイアスの視覚化 ![ベータ・タグ](images/beta.png)
{: #mf-monitor-bias-viz}

バイアスの可能性が検出されると、{{site.data.keyword.aios_short}} はいくつかの機能を実行して、このバイアスが実際に存在するのかを確認します。 {{site.data.keyword.aios_short}} は、モニター対象値を参照値に置き換え、この新しいレコードをモデルで実行することでデータを摂動します。 そうすると、結果の出力は、バイアスが緩和された出力となります。 さらに {{site.data.keyword.aios_short}} はシャドーのバイアス緩和モデルを訓練し、それを使用して、モデルがバイアスのある予測を行っているときにそれを検知します。 

公平性と正解率の計算には 2 つの異なるデータ・セットが使用されます。 公平性は、ペイロードおよび摂動されたデータを使用して計算されます。 正解率は、フィードバック・データを使用して計算されます。 正解率を計算するために、{{site.data.keyword.aios_short}} では、フィードバック・テーブルにのみ存在する、手動でラベル付けされたデータが必要になります。

これらの判定の結果は、バイアスの視覚化で確認できます。バイアスの可視化には次のビューが含まれます。 

- **ペイロードと摂動済み**: 選択した時間に関して受信した評価要求が含まれます。評価に必要な最小数のレコードがなかった場合には、それに加えてそれより前の時間のレコードも含まれます。 モニター対象の特徴量の値に変更があると、追加の摂動/合成されたレコードも含まれます。このレコードはモデルの応答のテストに使用されます。

   以下のペイロードと摂動済みの詳細情報に注目してください。

   - この時間にペイロード・テーブルから読み取られるレコードの数
   - それより前の時間にペイロード・テーブルから読み取られる追加のレコード数 (例えば、公平性構成内の `min_records` 値が 1000 に設定されており、午後 2 時から 3 時までの間にレコードが 10 個しか追加されない場合、システムは最小要件を満たすために、それより前の時間から追加の 990 個のレコードを読み取ります。)
   - 公平性属性あたりの摂動されたレコード
   - バイアスを計算する必要があるデータ・フレーム内の、最古のレコードのタイム・スタンプ
   - バイアスを計算する必要があるデータ・フレーム内の、最新のレコードのタイム・スタンプ

  ![ペイロードと摂動済みの例](images/payload&perturbed.png)



- **ペイロード**: 選択した時間に関してモデルが受信した実際の評価要求。

   以下のペイロードの詳細情報に注目してください。
   
   - ペイロード・テーブルから読み取られる/バイアス緩和済み操作が実行されるレコードの数
   - バイアスを計算する必要があるデータ・フレーム内の、最古のレコードのタイム・スタンプ
   - バイアスを計算する必要があるデータ・フレーム内の、最新のレコードのタイム・スタンプ


  ![ペイロード・データの例](images/payload.png)

- **訓練**: モデルを訓練するための訓練データ・レコード。

   以下の訓練の詳細情報に注目してください。
   
   - 訓練データ・レコードの数。 訓練データは 1 回読み取られ、分布は `subscription/fairness_configuration` 変数に保管されます。 分布の計算中に、訓練データ・レコードの数を調べて、同じ分布内に保管する必要もあります。 また、訓練データが変更されると (つまり `POST /data_distribution` コマンドが再実行されると)、 `fairness_configuration/training_data_distribution` 変数内でこの値が更新されます。 指標の送信中に、この値も送信する必要があります。
   - 訓練データが前回処理された (初めてかそれ以降の更新) 時刻

  ![訓練データの例](images/training.png)
   

   
- **バイアス緩和済み**: ランタイムと摂動済みのデータを処理後のバイアス緩和アルゴリズムの出力。

   以下のバイアス緩和済みの詳細情報に注目してください。
   
   - ペイロード・テーブルから読み取られる/バイアス緩和済み操作が実行されるレコードの数
   - バイアスを実行するために読み取られ、その結果バイアス緩和もされる追加のレコード数。 `「ペイロードと摂動済み」`で選択した数と同じ数です
   - 公平性属性あたりの摂動されたレコード
   - バイアスを計算する必要があるデータ・フレーム内の、最古のレコードのタイム・スタンプ
   - バイアスを計算する必要があるデータ・フレーム内の、最新のレコードのタイム・スタンプ
   - バイアス緩和済みビューのヘッダー部分に、前および後の公平性の値が表示されます。 
      - **後**の正解率は、フィードバック・データを取得してアクティブなバイアス緩和 API に送信して計算されます。 この API は、バイアス緩和後の予測を返します。 フィードバック・データには、手動ラベルも含まれています。 正解率を計算するために、手動ラベルがバイアス緩和後の予測と比較されます。 この API は、バイアス緩和後の予測を返します。 フィードバック・テーブルには、手動ラベルも含まれています。 正解率を計算するために、手動ラベルがバイアス緩和後の予測と比較されます。 
      - **前**の正解率は、同じフィードバック・データを使用して計算されます。 前の正解率を計算するために、フィードバック・データがモデルに送信されて予測が取得され、予測された値が手動ラベルと比較されて正解率が計算されます。

  ![バイアス緩和済みデータの例](images/debiased.png)
  
### 例
{: #mf-ex1}

あるデータ・ポイントにおいて、`Gender=Male` (参照値) ではモデルが好ましい結果を予測するものの、`Gender` を `Female` (モニター対象値) に変更して他の特徴量の値はすべて変更しないという方法でレコードを摂動すると、モデルが好ましくない結果を予測しました。 ペイロード・テーブルの最新 `N` 件のレコードと摂動されたデータ全体にわたって、モデルがバイアス挙動を示しているデータ・ポイントの数が十分にある場合、モデル全体でバイアスが現れていると見なされます。

### サポートされるモデル
{: #mf-supmo}

 {{site.data.keyword.aios_short}} では、項目ベクトルで何らかの構造化データを必要とするモデルと Python 関数でのみ、バイアス検出がサポートされています。

公平性指標は、以下の情報に基づいて計算されます。

- ペイロード・データの評価

適切なモニタリングのために、すべての評価要求は {{site.data.keyword.aios_short}} でログ記録する必要もあります。 {{site.data.keyword.pm_full}} エンジンの場合、ペイロード・データのロギングは自動化されています。

その他の機械学習エンジンの場合、Python クライアントか REST API を使用してペイロード・データを提供できます。

{{site.data.keyword.pm_full}} 以外の機械学習エンジンの場合、公平性モニタリングにより、モニター対象のデプロイメントに関する追加の評価要求が作成されます。
{: note}

{{site.data.keyword.aios_short}} ダッシュボードで、すべての指標値を経時的に確認できます。

![設定したしきい値を下回るドリフトが表示された公平性指標グラフ](images/fairness_metrics_001.png)

以下のように、好ましい結果と好ましくない結果などの、関連した詳細情報を検討できます。

![公平性の詳細](images/fairness_metrics_002.png)

以下のように、詳細トランザクションを表示できます。

![トランザクションのリストが表示された、公平性に関するグラフ](images/fairness_metrics_003.png)

推奨されるバイアス緩和済みの評価エンドポイントを表示できます。

![バイアス緩和済みの評価エンドポイントの詳細](images/fairness_metrics_004.png)

### サポートされている公平性指標
{: #anlz_metrics_supfairmets}

以下の公平性指標が {{site.data.keyword.aios_short}} によってサポートされています。

- [グループに関する公平性](https://test.cloud.ibm.com/docs/services/ai-openscale?topic=ai-openscale-quality_group)

以下の保護属性が {{site.data.keyword.aios_short}} によってサポートされています。 

- [性別](/docs/services/ai-openscale?topic=ai-openscale-quality_group#quality_group-sex)
- [人種](/docs/services/ai-openscale?topic=ai-openscale-quality_group#quality_group-ethnicity)
- [婚姻状態](/docs/services/ai-openscale?topic=ai-openscale-quality_group#quality_group-marital)
- [年齢](/docs/services/ai-openscale?topic=ai-openscale-quality_group#quality_group-age)
- [郵便番号](/docs/services/ai-openscale?topic=ai-openscale-quality_group#quality_group-zip)


### サポートされている公平性の詳細
{: #anlz_metrics_supfairdets}

以下の公平性指標に関する詳細が {{site.data.keyword.aios_short}} によってサポートされています。

- グループごとの好ましい割合
- すべての公平性グループに関する公平性の平均

```
                          (モニター対象グループにおける好ましい結果の割合
差別的効果率 =  ____________________________________________
                          (参照グループにおける好ましい結果の割合)
```

- モニター対象グループごとのデータの分布
- ペイロード・データの分布
