---

copyright:
  years: 2018, 2019
lastupdated: "2019-06-11"

keywords: fairness, fairness monitor

subcollection: ai-openscale

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}

# 公平性
{: #mf-monitor}

公平性はデプロイメントにバイアスがあるかどうかをモニターするもので、さまざまな集団を対象に公平な結果を得ることができるようにします。
{: shortdesc}

## 公平性について
{: #mf-understand}

{{site.data.keyword.aios_short}} は、デプロイ済みモデルを実行時に調べ、バイアスがあるかどうかを確認します。 デプロイ済みモデルのバイアスを検出するには、公平性属性 (Age、Gender など) を定義する必要があります。詳しくは、以下の[公平性モニターの構成](#mf-config)を参照してください。

{{site.data.keyword.aios_short}} でのバイアス検査を有効にするため、Watson {{site.data.keyword.pm_short}}でモデルまたは関数の出力スキーマを指定する必要があります。 出力スキーマは、`store_model` API のメタデータ部分で `client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA` プロパティーを使用して指定できます。 詳しくは、[WML クライアントの資料 ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](http://wml-api-pyclient-dev.mybluemix.net/#repository){: new_window} を参照してください。

### 処理の流れ
{: #mf-works}

公平性モニターを構成する前に、理解しておくべき重要な概念がいくつかあります。

- *公平性属性*: モデルでバイアスが現れる可能性のあるモデル属性です。 例えば、公平性属性 **`Gender`** の場合、モデルでは特定の性別値 (`Female`、`Transgender` など) にに対してバイアスが現れる可能性があります。 公平性属性のもう 1 つの例が **`Age`** です。モデルで特定の年齢グループ (`18 to 25` など) に属する人々に対してバイアスが現れる可能性があります。

- *参照値/モニター対象値*: 公平性属性の値は、「参照値」と「モニター対象値」という 2 種類の別個のカテゴリーに分割されます。 モニター対象値とは、不公平な判断をされる可能性がある値です。 **`Gender`** のような公平性属性の場合、モニター対象値は `Female` と `Transgender` などになります。 **`Age`** のような数値の公平性属性の場合、モニター対象値は `[18-25]` などになります。 特定の公平性属性のモニター対象値以外のすべての値は、参照値として扱われます (例: `Gender=Male`、`Age=[26,100]` など)。

- *好ましい結果/好ましくない結果*: モデルの出力は、「好ましい」または「好ましくない」のいずれかに分類されます。 例えば、モデルで融資の申請が受理されるかどうかを予測する場合には、好ましい結果は `Loan Granted` や `Loan Partially Granted` などで、好ましくない結果は `Loan Denied` などになります。 したがって、好ましい結果とは肯定的と見なされる結果で、好ましくない結果とは否定的と見なされる結果です。

{{site.data.keyword.aios_short}} アルゴリズムは、ペイロード・ロギング・テーブルの最新 `N` 件のレコードを使用して、1 時間ごとにバイアスを計算します (`N` の値は、公平性の構成時に指定します)。 このアルゴリズムはこれら最新の `N` 件のレコードを摂動して追加データを生成します。

この摂動は、公平性属性の値を参照値からモニター対象値 (またはこの逆方向) に変更することで行われます。 摂動されたデータはモデルに送られ、その動作が評価されます。 このアルゴリズムはペイロード・テーブルの最新 `N` 件のレコードと、摂動されたデータに対するモデルの動作を調べ、モデルがバイアス挙動を示しているかどうかを判定します。

結合されたこのデータ・セットでモニター対象クラスの好ましい結果の割合が、参照クラスの好ましい結果の割合よりも低く、その差がしきい値を超えた場合は、モデルにバイアスがあると見なされます。 このしきい値は、公平性の構成時に指定します。

公平性値は 100% を超えることがあります。これは、モニター対象グループが得る好ましい結果が参照グループより多いことを意味します。 また、新しい予測リクエストが送信されない場合は、公平性値は一定のままになります。
{: note}

### バイアスの視覚化 ![ベータ・タグ](images/beta.png)
{: #mf-monitor-bias-viz}

バイアスの可能性が検出されると、{{site.data.keyword.aios_short}} はいくつかの機能を実行して、このバイアスが実際に存在するのかを確認します。{{site.data.keyword.aios_short}} は、モニター対象値を参照値に置き換え、この新しいレコードをモデルで実行することでデータを摂動します。そうすると、結果の出力は、バイアスが緩和された出力となります。さらに {{site.data.keyword.aios_short}} はシャドーのバイアス緩和モデルを訓練し、それを使用して、モデルがバイアスのある予測を行っているときを検出します。これらの判定の結果は、バイアスの視覚化で確認できます。バイアスの可視化には次のビューが含まれます。 

- **ペイロードと摂動済み**: 選択した時間に関して受信した評価要求が含まれます。評価に必要な最小数のレコードがなかった場合には、それに加えてそれより前の時間のレコードも含まれます。 モニター対象の特徴量の値に変更があると、追加の摂動/合成されたレコードも含まれます。このレコードはモデルの応答のテストに使用されます。

   以下のペイロードと摂動済みの詳細情報に注目してください。

   - この時間にペイロード・テーブルから読み取られるレコードの数
   - それより前の時間にペイロード・テーブルから読み取られる追加のレコード数 (例えば、公平性構成内の `min_records` 値が 1000 に設定されており、午後 2 時から 3 時までの間にレコードが 10 個しか追加されない場合、システムは最小要件を満たすために、それより前の時間から追加の 990 個のレコードを読み取ります。)
   - 公平性属性あたりの摂動されたレコード
   - バイアスを計算する必要があるデータ・フレーム内の、最古のレコードのタイム・スタンプ
   - バイアスを計算する必要があるデータ・フレーム内の、最新のレコードのタイム・スタンプ

  ![ペイロードと摂動済みの例](images/payload&perturbed.png)



- **ペイロード**: 選択した時間に関してモデルが受信した実際の評価要求。

   以下のペイロードの詳細情報に注目してください。
   
   - ペイロード・テーブルから読み取られる/バイアス緩和済み操作が実行されるレコードの数
   - バイアスを計算する必要があるデータ・フレーム内の、最古のレコードのタイム・スタンプ
   - バイアスを計算する必要があるデータ・フレーム内の、最新のレコードのタイム・スタンプ


  ![ペイロード・データの例](images/payload.png)

- **訓練**: モデルを訓練するための訓練データ・レコード。

   以下の訓練の詳細情報に注目してください。
   
   - 訓練データ・レコードの数。 訓練データは 1 回読み取られ、分布は `subscription/fairness_configuration` 変数に保管されます。分布の計算中に、訓練データ・レコードの数を調べて、同じ分布内に保管する必要もあります。 また、訓練データが変更されると (つまり `POST /data_distribution` コマンドが再実行されると)、 `fairness_configuration/training_data_distribution` 変数内でこの値が更新されます。指標の送信中に、この値も送信する必要があります。
   - 訓練データが前回処理された (初めてかそれ以降の更新) 時刻

  ![訓練データの例](images/training.png)
   

   
- **バイアス緩和済み**: ランタイムと摂動済みのデータを処理後のバイアス緩和アルゴリズムの出力。

   以下のバイアス緩和済みの詳細情報に注目してください。
   
   - ペイロード・テーブルから読み取られる/バイアス緩和済み操作が実行されるレコードの数
   - バイアスを実行するために読み取られ、その結果バイアス緩和もされる追加のレコード数。 `「ペイロードと摂動済み」`で選択した数と同じ数です
   - 公平性属性あたりの摂動されたレコード
   - バイアスを計算する必要があるデータ・フレーム内の、最古のレコードのタイム・スタンプ
   - バイアスを計算する必要があるデータ・フレーム内の、最新のレコードのタイム・スタンプ

  ![バイアス緩和済みデータの例](images/debiased.png)
  
### 例
{: #mf-ex1}

あるデータ・ポイントにおいて、`Gender=Male` (参照値) ではモデルが好ましい結果を予測するものの、`Gender` を `Female` (モニター対象値) に変更して他の特徴量の値はすべて変更しないという方法でレコードを摂動すると、モデルが好ましくない結果を予測しました。 ペイロード・テーブルの最新 `N` 件のレコードと摂動されたデータ全体にわたって、モデルがバイアス挙動を示しているデータ・ポイントの数が十分にある場合、モデル全体でバイアスが現れていると見なされます。

### サポートされるモデル
{: #mf-supmo}

 {{site.data.keyword.aios_short}} では、項目ベクトルで何らかの構造化データを必要とするモデルと Python 関数でのみ、バイアス検出がサポートされています。

## 公平性モニターの構成
{: #mf-config}

1.  *「公平性モニターとは」*ページで**「次へ」**をクリックして、構成プロセスを開始します。

    ![「公平性モニターとは」ページ](images/fair-what-is.png)

1.  *「モニターする特徴量の選択」*ページで、使用する公平性属性を見つけて選択し、**「次へ」**をクリックします。

    公平性のデータ・タイプが、カテゴリカル、数値 (整数)、浮動小数点、または倍精度の特徴量だけがサポートされます。 他のデータ・タイプの特徴量はサポートされません。
    {: note}

    この例では、`Age`、`Gender`、および `Ethnicity` の各特徴量が選択されています。

    ![選択された特徴量を示す「モニターする特徴量の選択」ページ](images/fair-select-feature.png)

    **「次へ」**をクリックして先に進みます。

1.  各特徴量には構成に関する特定の要件があります。 この例では、「参照グループ」と「モニター対象グループ」の **`Age`** の範囲を定義するため、各グループに値を手動で直接入力します。

    この例では、**`Age`** 公平性属性について、18 歳から 25 歳の年齢の人々に対してモデルでバイアスが生じる可能性があると考えられる場合、モニター対象グループの値は `[18-25]`、参照グループの値は `[26-100]` のようになります。 **`Gender`** 公平性属性の場合、参照グループの値は `Male`、モニター対象グループの値は `Female` と `Transgender` のようになります。

    ![年齢設定の構成](images/fair-config-age.png)

    **「次へ」**をクリックして先に進みます

1.  **`Age`** の公平性のしきい値を設定します。

    公平性しきい値は、モニター対象グループの好ましい結果の割合を参照グループの好ましい結果の割合と比較したときの受け入れ可能な差異を指定するときに使用します。

    融資が許可される申請者 (`favorable outcome=loan granted`) と融資が許可されない申請者 (`unfavorable outcome=loan denied`) を予測するモデルがあるとします。 また、年齢のモニター対象値は `[18,25]`、参照値は `[26,100]` です。 バイアス検出アルゴリズムの実行時に、最新 `N` 件のレコードと摂動されたデータで年齢グループ `[18,25]` の申請者の好ましい結果の割合が `50%` であり、年齢グループ `[26,100]` の申請者の好ましい結果の割合が `70%` である場合、公平性は 50*100/70 = 71.42 と計算されます。

    公平性しきい値が 80% に設定されている場合、計算された公平性はこのしきい値より低いため、アルゴリズムによりこのモデルにバイアスがあることを示すフラグが立てられます。 ただし、しきい値が 70% に設定されている場合、このモデルはバイアスがあるものとして報告されません。

    ![年齢設定の構成](images/fair-config-age-limit.png)

    公平性しきい値を選択したら、**「次へ」**をクリックします。

1.  特徴量 `Gender` と `Ethnicity` を同様の方法で構成します。

     ![性別設定の構成](images/fair-config-gender.png)

     ![民族設定の構成](images/fair-config-ethnic.png)

     **注**: これらの画面で入力する値は、モデル・予測エンドポイントに送信される (その後ペイロード・テーブルに追加される) 値である必要があります。 データが予測エンドポイントへの送信前に操作された場合は、操作後の値を入力してください。 例えば、元のデータの *Gender* の値 `Male` と `Female` が操作され、予測エンドポイントに送信されるデータが `M` と `F` になった場合、この画面では `M` と `F` を入力してください。

     各特徴量で処理が完了したら、**「次へ」**をクリックします。

1.  次に、モデルで好ましい結果を表す値を指定します。 モデル出力スキーマにマッピング列が含まれている場合、値は[訓練データ](/docs/services/ai-openscale?topic=ai-openscale-trainingdata#trainingdata)の `label` 列から得られます。 WML では、`prediction` 列の値は常に倍精度になります。 マッピング列は、この `prediction` 値からクラス・ラベルへのマッピングを指定するために使用されます。

    例えば、`prediction` 値が `1.0` の場合、マッピング列の値に `Loan denied` を設定することができます。これは、モデルの予測が `Loan denied` であることを示します。 それで、モデル出力スキーマにマッピング列が含まれている場合、マッピング列に存在する値を使用して好ましい値と好ましくない値を指定します。

    ただし、モデル出力スキーマにマッピング列がない場合、`prediction` 列の値を使用して、好ましい値と好ましくない値を指定する必要があります (`0.0`、`1.0` など)

     ![結果の構成](images/fair-config-outcome.png)

     **「次へ」**をクリックします。

1.  最後に、評価データ・セットで最小限の数のレコードを得られるまで公平性の測定を行わないようにするため、最小サンプル・サイズを設定します。 これにより、サンプル・サイズが小さすぎて結果にゆがみが生じることがなくなります。 バイアス検査が実行されるたびに、最小サンプル・サイズを使用してバイアス計算対象のレコードの数が決定されます。

     ![サンプル・サイズの構成](images/fair-config-sample.png)

1.  **「次へ」**ボタンをクリックします。

    選択内容の要約が確認のために表示されます。 変更が必要な場合は、該当するセクションの**「編集」**リンクをクリックします。

    **「別の特徴量の追加」**リンクを選択すると、特徴量選択画面に戻ります。ここで、公平性モニターに特徴量 (`City`、`Zip Code`、`Account Balance` など) を追加することもできます。

1.  **「保存」**をクリックして構成を完了します。

### バイアス緩和の処理の流れについて
{: #mf-debias}

次に、バイアス緩和後の予測エンドポイントを示す画面が表示されます。

  ![バイアス緩和 API](images/fair-debias-api.png)

バイアス緩和後の予測エンドポイントは、デプロイ済みモデルの通常のスコアリング・エンドポイントと完全に同じように使用できます。 このエンドポイントは、デプロイ済みモデルの応答を返すだけでなく、`debiased_prediction` および `debiased_probability` という 2 つの追加の列も返します。

- `debiased_prediction` 列にはバイアス緩和後の予測値が入ります。 Watson Machine Learning (WML) の場合、これは予測のエンコード表現です。 例えばモデルの予測が「Loan Granted」または「Loan Denied」のいずれかである場合、WML ではこれら 2 つの値をそれぞれ「0.0」および「1.0」としてエンコードできます。 `debiased_prediction` 列には、このようなバイアス緩和後の予測のエンコード表現が入ります。

- 一方、`debiased_probability` 列は、バイアス緩和後の予測の確率を表します。 これは倍精度値の配列であり、各値はいずれかの予測クラスに属するバイアス緩和後の予測の確率を表します。

`decoded-target` として `modeling-role` が設定されている列を含んだ出力スキーマに列がある場合、`debiased_decoded_target` という別の列も返されます。

- `debiased_decoded_target` 列には、バイアス緩和後の予測のストリング表現が入ります。 前述の例では、予測値が「0.0」または「1.0」のいずれかである場合、`debiased_decoded_target` には「Loan Granted」または「Loan Denied」のいずれかが入ります。

このエンドポイントを実動アプリケーションから直接呼び出すほうが、モデル処理エンジン (Watson Machine Learning、Amazon Sagemaker、Microsoft Azure ML Studio など) にデプロイされたモデルの予測エンドポイントを直接呼び出すより理想的です。 このようにすると、{{site.data.keyword.aios_short}} は、モデル・デプロイメントのペイロード・ロギング・テーブルに `debiased` の値も格納します。 その後、このエンドポイントで行われたすべての予測は自動的にバイアス緩和されます。

このエンドポイントは実行時のバイアスに対処するので、ペイロード・ロギング・テーブルからの最新の予測データに対しバックグラウンド検査を引き続き実行し、送信された予測リクエストのバイアスを排除するために使用されるバイアス緩和モデルを更新し続けます。 このように、{{site.data.keyword.aios_short}} には、最新の着信データを取り込む機能と、バイアスを検出して緩和する機能があるので、常に最新状態に維持されます。

最後に {{site.data.keyword.aios_short}} は、データが現時点で受け入れ可能でバイアスがないものと判定するために、しきい値を使用します。 そのしきい値として取られる値は、公平性モニターで構成済みのすべての公平性属性に対して設定されたしきい値の中の最小値です。

### 次のステップ
{: #mf-next}

*「モニターの構成」*ページで、別のモニタリング・カテゴリーを選択できます。
