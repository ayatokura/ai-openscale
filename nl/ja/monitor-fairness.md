---

copyright:
  years: 2018, 2019
lastupdated: "2019-03-28"

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}

# 公平性
{: #mf-monitor}

公平性とは、デプロイメントでバイアスをモニターすることで、さまざまな集団の間で結果を公平にする助けになります。
{: shortdesc}

## 公平性について
{: #mf-understand}

{{site.data.keyword.aios_short}} は実行時に、デプロイされているモデルでバイアスを検査します。デプロイされているモデルのバイアスを検出するには、下記の[公平性モニターの構成](#mf-config)で詳述されているように、年齢や性別などのフィーチャー要件を定義しなければなりません。

{{site.data.keyword.aios_short}} でバイアス検査を有効にするには、Watson Machine Learning (WML) でモデルまたは関数の出力スキーマを指定する必要があります。出力スキーマを指定するには、`store_model` API のメタデータ部分の `client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA` プロパティーを使用します。詳細については、[WML クライアントの資料 ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](http://wml-api-pyclient-dev.mybluemix.net/#repository){: new_window} を参照してください。

### 動作内容
{: #mf-unf}

公平性モニターを構成する前に、以下の鍵となる概念を理解しておくことは重要です。

- *公平性属性*: バイアスを示す可能性のあるモデルのモデル属性です。例えば、公平性属性 **`Gender`** の場合、そのモデルでは特定の性別の値 (`Female` や `Transgender` など) に対してバイアスが生じることがあります。別の例として、公平性属性 **`Age`** の場合、そのモデルでは `18 to 25` のような年齢グループの人々にバイアスが示されることがあります。

- *参照 / モニター対象の値*: 公平性属性の値は、参照とモニター対象という 2 種類のカテゴリーに分割されます。モニター対象値とは、弁別対象にしようとしている値のことです。**`Gender`** のような公平性属性の場合、モニター対象値は `Female` や `Transgender` のようになります。**`Age`** などの数値の公平性属性の場合、モニター対象値は `[18-25]` のようになります。特定の公平性属性のその他の値はすべて参照値と見なされます。例えば、`Gender=Male` や `Age=[26,100]` のようになります。

- *好ましい / 好ましくない結果*: モデルの出力は、好ましいか好ましくないかで分類されます。例えば、ある人が融資を受けられるかどうかを予測するモデルの場合、好ましい結果は `Loan Granted` または `Loan Partially Granted` のようになり、好ましくない結果は `Loan Denied` のようになります。つまり、好ましい結果とは肯定的な結果と見なされる結果のことで、好ましくない結果とは否定的と見なされる結果のことです。

{{site.data.keyword.aios_short}} アルゴリズムは、ペイロード・ロギング・テーブル内の最新の `N` 個のレコードを使用して、時間単位でバイアスを計算します。`N` の値は、公平性の構成時に指定されます。このアルゴリズムは、これらの最新の `N` 個のレコードを摂動し、追加のデータを生成します。

摂動とは、公平性属性の値を参照からモニター対象に変更したり、モニター対象から参照に変更したりすることです。その後、摂動されたデータがモデルに送信されて動作が評価されます。このアルゴリズムは、ペイロード・テーブル内の `N` 個のレコードと摂動されたデータに関するモデルの動作を参照し、そのモデルがバイアスのある仕方で動作しているかどうかを決定します。

モデルは、この組み合わせのデータ・セット全体で、いくつかのしきい値を規準に、モニター対象のクラスの好ましい結果の割合が参照クラスの好ましい結果の割合を下回る場合に、バイアスがあると見なされます。このしきい値は、公平性の構成時に指定されます。

公平性の値が 100% を超えることがあります。この場合、モニター対象グループが受け取った好ましい結果が、参照グループより多かったことを意味します。また、新しいスコアリング要求が送信されないと、公平性の値は一定のままになります。
{: note}

### 例
{: #mf-une}

あるデータ・ポイントで、`Gender=Male` (参照値) の場合、モデルは好ましい結果を予測するものの、`Gender` を `Female` (モニター対象値) に変更してレコードを摂動しつつその他のフィーチャー値はすべて同じ値のままにすると、モデルは好ましくない結果を予測するとします。モデルに、バイアスのある仕方で動作しているデータ・ポイントが (ペイロード・テーブル内の `N` 個のレコードと摂動されたデータの全体で) 十分ある場合、そのモデル全体はバイアスを示していると考えられます。

### サポートされるモデル
{: #mf-uns}

 {{site.data.keyword.aios_short}} は、フィーチャー・ベクトル内で何らかの種類の構造化データを予期しているモデルと Python 関数に限り、バイアス検出をサポートします。

## 公平性のモニターの構成
{: #mf-config}

1.  *「公平性は? (What is Fairness?)」*ページから、**「次へ」**をクリックして構成プロセスを開始します。

    ![「公平性は? (What is Fairness?)」ページ](images/fair-what-is.png)

1.  *「モニターするフィーチャーの選択 (Select the features to monitor)」*ページで、使用しようとしている公平性属性を見つけて選択し、**「次へ」**をクリックします。

    **注**: 公平性データ・タイプがカテゴリー、数値 (整数)、浮動小数点、または倍精度のフィーチャーのみサポートされています。その他のデータ・タイプのフィーチャーはサポートされていません。

    この例では、`Age`、`Gender`、`Ethnicity` フィーチャーが選択されています。

    ![「モニターするフィーチャーの選択 (Select the features to monitor)」ページと選択項目](images/fair-select-feature.png)

    **「次へ」**をクリックして先に進みます。

1.  各フィーチャーには、構成に対する特定の要件があります。この例では、参照グループとモニター対象グループの **`Age`** 範囲を、各グループ内の値を手動で直接入力して定義します。

    この例では、**`Age`** 公平性属性について、18 歳から 25 歳までの人に対してモデルがバイアスを示す可能性があると思われる場合、モニター対象グループの値は `[18-25]` になり、参照グループの値は `[26-100]` になります。**`Gender`** 公平性属性については、参照グループの値は `Male` になり、一方モニター対象グループの値は `Female` と `Transgender` になることがあります。

    ![年齢設定の構成](images/fair-config-age.png)

    **「次へ」**をクリックして先に進みます。

1.  **`Age`** に関する公平性のしきい値限度を設定します。

    公平性しきい値を使用して、モニター対象グループの好ましい結果の割合と参照グループの好ましい結果の割合を比較した際の受け入れられる差分を指定します。

    融資を受けられる人 (`favorable outcome=loan granted`) と受けられない人 (`unfavorable outcome=loan denied`) を予測するモデルを想定します。さらに、年齢のモニター対象値が `[18,25]` で、参照値が `[26,100]` であるとします。バイアス検出アルゴリズムの実行時に、最新の `N` 個のレコードと摂動されたデータ内で年齢グループ `[18,25]` の人の好ましい結果の割合が `50%` で、年齢グループ `[26,100]` の人の好ましい結果の割合が `70%` であると検出された場合、公平性は 50*100/70 = 71.42 と計算されます。

    公平性しきい値が 80% に設定されている場合、計算された公平性がこのしきい値を下回っているので、このアルゴリズムはこのモデルにバイアスがあるとしてフラグを立てます。しかし、しきい値が 70% に設定されている場合は、モデルにバイアスがあると報告されません。

    ![年齢設定の構成](images/fair-config-age-limit.png)

    公平性しきい値を選択したら、**「次へ」**をクリックします。

1.  以下のように、同じ方法で `Gender` と `Ethnicity` のフィーチャーを構成します。

     ![性別設定の構成](images/fair-config-gender.png)

     ![民族設定の構成](images/fair-config-ethnic.png)

     **注**: モデルのスコアリング・エンドポイントに送信されている (さらにその後ペイロード・テーブルに追加される) 値を、これらの画面に入力する必要があります。データをスコアリング・エンドポイントに送信する前に操作しようとしている場合は、操作された値を入力してください。例えば、元のデータの *Gender* の値が `Male` と `Female` で、操作が行われてスコアリング・エンドポイントに送信されたデータが `M` と `F` だった場合は、この画面で `M` と `F` を入力します。

     各フィーチャーを構成したら、**「次へ」**をクリックします。

1.  続いて、モデルに関する好ましい結果を表す値を指定します。モデルの出力スキーマにマッピング列が含まれている場合は、値はトレーニング・データ内の `label` 列から派生します。WML では、`prediction` 列には常に倍精度値が入ります。マッピング列は、この `prediction` 値からクラス・ラベルへのマッピングを指定するのに使用されます。

    例えば、`prediction` 値が `1.0` の場合、マッピング列の値は `Loan denied` になることがあります。この場合、モデルの予測が `Loan denied` であることを暗黙に示しています。つまり、モデルの出力スキーマにマッピング列が含まれている場合は、マッピング列内にある値を使用して好ましい値と好ましくない値を指定します。

    しかし、モデルの出力スキーマ内にマッピング列がない場合は、`prediction` 列の値 (`0.0` や `1.0` など) を使用して好ましい値と好ましくない値を指定する必要があります。

     ![結果の構成](images/fair-config-outcome.png)

     **「次へ」**をクリックします。

1.  最後に最小サンプル・サイズを設定します。設定すると、評価データ・セット内で最小限のレコード数が使用可能になるまでは、公平性の測定が進まなくなります。そのため、サンプル・サイズが小さすぎて結果が偏るということはなくなります。バイアス検査を実行するたびに、最小サンプル・サイズを使用して、バイアスが計算されるレコードの数が決定されます。

     ![サンプル・サイズの構成](images/fair-config-sample.png)

1.  **「次へ」**ボタンをクリックします。

    検討用に選択内容の要約が表示されます。変更する場合は、その選択項目に関する**「編集」**リンクをクリックします。

    **「別のフィーチャーの追加 (Add another feature)」**リンクを選択してフィーチャー選択画面に戻り、公平性モニターにさらに `City`、`Zip Code`、`Account Balance` などの値を追加することもできます。

1.  **「保存」**をクリックし、構成を完了します。

### バイアス除去機能の理解
{: #mf-debias}

続いて、バイアス除去されるスコアリング・エンドポイントを指定する画面が表示されます。

  ![バイアス除去 API](images/fair-debias-api.png)

バイアス除去されたスコアリング・エンドポイントは、デプロイされているモデルの通常のスコアリング・エンドポイントと全く同様に使用できます。デプロイされているモデルの応答に加えて、`debiased_prediction` および `debiased_probability` と呼ばれる 2 つの追加の列が戻されます。

- `debiased_prediction` 列には、バイアス除去された予測値が含まれます。Watson Machine Learning (WML) の場合、この値は予測のエンコードされた表現になります。例えば、モデルの予測が「Loan Granted」または「Loan Denied」の場合、WML ではこれらの 2 つの値をそれぞれ「0.0」と「1.0」にエンコードできます。`debiased_prediction` 列には、このようなバイアス除去された予測のエンコードされた表現が含まれます。

- 他方、`debiased_probability` 列は、バイアス除去された予測の確率を表します。これは倍精度値の配列で、各値は予測クラスの 1 つに属するバイアス除去された予測の確率を表します。

`modeling-role` が `decoded-target` である列を含む出力スキーマ内の列がある場合、さらに別の列 (`debiased_decoded_target`) も返されます。

- `debiased_decoded_target` 列には、バイアス除去された予測のストリング表現が含まれます。上記の予測値が「0.0」または「1.0」の例では、`debiased_decoded_target` には「Loan Granted」または「Loan Denied」が含まれます。

モデル・サービス提供エンジン (Watson Machine Learning、Amazon Sagemaker、Microsoft Azure ML Studio など) でデプロイされたモデルのスコアリング・エンドポイントを直接呼び出すのではなく、実動アプリケーションからこのエンドポイントを直接呼び出すのが理想的です。この場合、{{site.data.keyword.aios_short}} はモデル・デプロイメントのペイロード・ロギング・テーブル内に `debiased` 値も保管します。その後、このエンドポイントを使用して行われるスコアリングは、すべて自動的にバイアス除去されます。

このエンドポイントは実行時バイアスに対応するので、ペイロード・ロギング・テーブルからの最新のスコアリング・データの経歴検査が継続的に実行され、送信されるスコアリング要求のバイアス除去に使用されるバイアス緩和モデルが引き続き更新されます。したがって {{site.data.keyword.aios_short}} は、最新の着信データと、バイアスを検出して緩和する動作により、常に最新の状態に保たれます。

最後に、{{site.data.keyword.aios_short}} でしきい値を使用して、現在データが受け入れ可能か、またバイアス除去されていると見なされるかが決定されます。このしきい値は、公平性モニターで、構成されているすべての公平性属性のしきい値セット内の最小値として採用されます。

## 次のステップ
{: #mf-next}

*「モニターの構成」*ページから、別のモニター・カテゴリーを選択できます。
